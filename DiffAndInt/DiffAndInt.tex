%--------------------------------------------------------------------
% NE 155 (intro to numerical simulation of radiation transport)
% Spring 2014

% formatting
\documentclass[12pt]{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

\usepackage{setspace}
\onehalfspacing

\setlength{\parindent}{0mm} \setlength{\parskip}{1em}


% packages
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{times}
\renewcommand{\ttdefault}{cmtt}
\usepackage{amsmath}
\usepackage{graphicx} % for graphics files

% Draw figures yourself
\usepackage{tikz} 

% The float package HAS to load before hyperref
\usepackage{float} % for psuedocode formatting
\usepackage{xspace}

% from Denovo methods manual
\usepackage{mathrsfs}
\usepackage[mathcal]{euscript}
\usepackage{color}
\usepackage{array}

\usepackage[pdftex]{hyperref}

\newcommand{\nth}{n\ensuremath{^{\text{th}}} }
\newcommand{\ve}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\macro}{\ensuremath{\Sigma}}
\newcommand{\vOmega}{\ensuremath{\hat{\Omega}}}

\newcommand{\cc}[1]{\ensuremath{\overline{#1}}}
\newcommand{\ccm}[1]{\ensuremath{\overline{\mathbf{#1}}}}


%--------------------------------------------------------------------
%--------------------------------------------------------------------
\begin{document}
\begin{center}
{\bf NE 155, Classes 13 \& 14, S14 \\
Differentiation \& Integration \\ February 24 and 26, 2014}
\end{center}

\setlength{\unitlength}{1in}
\begin{picture}(6,.1) 
\put(0,0) {\line(1,0){6.25}}         
\end{picture}

%--------------------------------------------------------------------
\section{Differentiation}
\underline{Problem} Given a function $f(x)$ at $x_0, x_1, \dots, x_n$ approximate $f'(x)$ or $f''(x)$, etc. 

Numerical differentiation is  
\begin{itemize}
\item useful when a function is defined by 
\begin{itemize}
\item data
\item differential equations (ODEs, PDEs)
\end{itemize}
\item inherently sensitive to round-off error. 
\end{itemize}

\textbf{Example} Given $f \in C^2 [a,b]$ and let $x_0 \in [a,b]$, find an approximation to $f'(x_0)$.

We're going to come at this from \textbf{Taylor's theorem}.
%
\begin{align}
f(x) &= f(x_0) + f'(x_0)(x - x_0) + \frac{f''(c)}{2}(x-x_0)^2 \\
% 
\therefore f'(x_0) &= \frac{f(x) - f(x_0)}{(x - x_0)} - \frac{f''(c)}{2}(x-x_0) \\
%
\text{Let } h &= x-x_0 \rightarrow x = x_0 + h \\
%
\therefore f'(x_0) &= \underbrace{\frac{f(x_0 + h) - f(x_0)}{h}}_{\text{computable approx.}} - \frac{f''(c)}{2}h
\end{align}
%
We can extend this principle to get higher levels of accuracy. To do that we do a Taylor expansion for each point in our collection and choose how many points to combine and in what ways. 
%
\begin{center}
\begin{tikzpicture}
\draw (-.25,0)--(1.25,0);
\draw[dotted] (1.25,0)--(2.75,0);
\draw (2.75,0)--(5.25,0);
\draw[dotted] (5.25,0)--(6.75,0);
\draw (6.75,0)--(8.25,0);
%\draw (4,0)--(5.25,0);
\draw (0,-.25)--(0,.25);
\draw (1,-.25)--(1,.25);
%\draw (2,-.25)--(2,.25);
\draw (3,-.25)--(3,.25);
\draw (4,-.25)--(4,.25);
\draw (5,-.25)--(5,.25);
\draw (7,-.25)--(7,.25);
\draw (8,-.25)--(8,.25);
\node[below] at (0,-.25) {$x_0$};
\node[below] at (1,-.25) {$x_1$};
\node[below] at (3,-.25) {$x_{i-1}$};
\node[below] at (4,-.25) {$x_i$};
\node[below] at (5,-.25) {$x_{i+1}$};
\node[below] at (7,-.25) {$x_{n-1}$};
\node[below] at (8,-.25) {$x_n$};
\end{tikzpicture}
\end{center}

\begin{align}
f(x_0) &= f(x_0)\\
%
f(x_0 \pm h) &= f(x_0) \pm hf'(x_0) + h^2\frac{f''(x_0)}{2} \pm h^3\frac{f'''(x_0)}{6} + f^{(4)}(c_1)\frac{h^4}{24} \\
%
f(x_0 \pm 2h) &= f(x_0) \pm 2h f'(x_0) + 2 h^2 f''(x_0) \pm \frac{4}{3} h^3 f'''(x_0) + \frac{2}{3}h^4 f^{(4)}(c_2)
\end{align}


% ---------------------------------------------------------
\subsection{Forward difference:}
\underline{$O(h)$}: combine the point and the next point forward
\[f'(x_0) = \frac{f(x_0 + h) - f(x_0)}{h} - \frac{1}{2}hf''(c)\]

\underline{$O(h^2)$}: combine the point and the next two points forward
%
\begin{align}
a f(x_0) &+ b f(x_0 + h) + c f(x_0 + 2h) = f'(x_0) \\
%
a f(x_0) &+ b[f(x_0) + hf'(x_0) + h^2\frac{f''(x_0)}{2} + h^3\frac{f'''(x_0)}{6}] \nonumber \\
&+ c[f(x_0) + 2h f'(x_0) + 2 h^2 f''(x_0) + \frac{4}{3} h^3 f'''(x_0)] =f'(x_0) \\
%
(a + b &+ c)f(x_0) + h(b + 2c)f'(x_0) + h^2(\frac{b}{2} + 2c) f''(x_0) \nonumber \\
&+ h^3(\frac{b}{6} +  \frac{4c}{3}) f'''(\mu) = f'(x_0)
\end{align}
%
Use mean value theorem to get $\mu \in [c_1, c_2]$ to get only one term.

*KEY* set the coefficients to get what we want:
%
\begin{align}
(a + b + c) &= 0\\
h(b + 2c) &= 1\\
h^2(\frac{b}{2} + 2c) &= 0
\end{align}
%
We don't have more degrees of freedom, so we're left with $f'''$ for the error term. 

Solving all of that gives
%
\begin{align}
a &= -\frac{3}{2h} \\
b &= \frac{2}{h} \\
c &= \frac{1}{2h} \\
&\text{error term } = -\frac{1}{3}h^2 f'''(\mu) \\
\therefore \quad &\boxed{f'(x_0) = \frac{-3 f(x_0) + 4f(x_0 + h) - f(x_0 + 2h)}{2h} -\frac{1}{3}h^2 f'''(\mu)}
\end{align}


%--------------------------------------------------------------------
\subsection{Backward difference:}
Essentially, the signs all flip because we use points in the other direction.

\underline{$O(h)$}: combine the point and the next point backward
\[f'(x_0) = \frac{f(x_0) - f(x_0 - h)}{h} + \frac{1}{2}hf''(\mu)\]

\underline{$O(h^2)$}: combine the point and the next two points backward
%
\[f'(x_0) = \frac{3 f(x_0) - 4f(x_0 - h) + f(x_0 - 2h)}{2h} + \frac{1}{3}h^2 f'''(\mu)\]

%--------------------------------------------------------------------
\subsection{Central difference:}
Use points on either side (the average of forward and backward difference) $\rightarrow$ more accuracy for the same number of evaluation  points.

\underline{$O(h^2)$}: combine one point on either side
\[f'(x_0) = \frac{f(x_0 + h) - f(x_0 - h)}{2h} - \frac{1}{6}h^2 f'''(\mu)\]

\underline{$O(h^4)$}: combine two points on either side
\[f'(x_0) = \frac{f(x_0 - 2h) - 8f(x_0 - h) + 8f(x_0 + h) - f(x_0 + 2h)}{2h} - \frac{1}{30}h^4 f^{(5)}(\mu)\]

\subsubsection{Higher Order Derivatives}
By solving for different terms in the Taylor expansion, combining points, and solving for coefficients we can get other derivative terms as well. 

E.g. $a f(x_0 + h) + b f(x_0) + c f(x_0 - h) = f''(x_0)$

These are all $O(h^2)$:
\begin{align}
f''(x_0) &= \frac{f(x_0 - h) - 2f(x_0) + f(x_0 + h)}{h^2} + \frac{h^2}{12}f^{(4)}(\mu) \\
%
f^{(3)}(x_0) &= \frac{-f(x_0 - 2h) + 2f(x_0 - h) - 2f(x_0 + h) + f(x_0 + 2h)}{2h^3}\\
%
f^{(4)}(x_0) &= \frac{f(x_0 - 2h) - 4f(x_0 - h) +6f(x_0) - 4f(x_0 + h) + f(x_0 + 2h)}{h^4}
\end{align}

\subsubsection{Two Variables}
\begin{center}
\begin{tikzpicture}
\draw (-.25,0)--(7.25,0);
\draw (1,-.25)--(1,.25);
\draw (3,-.25)--(3,5.25);
\draw (4,-.25)--(4,5.25);
\draw (5,-.25)--(5,5.25);
\draw (7,-.25)--(7,.25);
\node[below] at (0,-.25) {$x_0$};
\node[below] at (1,-.25) {$x_1$};
\node[below] at (3,-.25) {$x_{i-1}$};
\node[below] at (4,-.25) {$x_i$};
\node[below] at (5,-.25) {$x_{i+1}$};
\node[below] at (7,-.25) {$x_n$};
\node at (3.5, 2) {$\Delta x$};
% begin y
\draw (0,-.25)--(0,7.25);
\draw (-.25,1)--(.25,1);
\draw (-.25,3)--(5.25,3);
\draw (-.25,4)--(5.25,4);
\draw (-.25,5)--(5.25,5);
\draw (-.25,7)--(.25,7);
\node[left] at (-.25, 0) {$y_0$};
\node[left] at (-.25,1) {$y_1$};
\node[left] at (-.25,3) {$y_{i-1}$};
\node[left] at (-.25,4) {$y_i$};
\node[left] at (-.25,5) {$y_{i+1}$};
\node[left] at (-.25,7) {$y_n$};
\node at (2,3.5) {$\Delta y$};
\end{tikzpicture}
\end{center}

\begin{align}
\frac{\partial^2 f_{i,j}}{\partial x^2} = \frac{\partial}{\partial x}\bigl(\frac{\partial f_{i,j}}{\partial x}\bigr) =
\frac{f_{i-1,j} - 2f_{i,j} + f_{i+1,j}}{\Delta x^2} \\
%
\frac{\partial^2 f_{i,j}}{\partial y^2} = \frac{\partial}{\partial y}\bigl(\frac{\partial f_{i,j}}{\partial y}\bigr) =
\frac{f_{i,j-1} - 2f_{i,j} + f_{i,j+1}}{\Delta y^2}
\end{align}



%--------------------------------------------------------------------
%-------------------------------------------------------------------
\section{Integration}
Why might we need to numerically integrate?
\begin{itemize}
\item The integrand, $f(x)$, is complicated enough so that its
indefinite or even definite integral over a special range cannot
be found.
\item The indefinite or definite integral can be found, but may take
long time to calculate it analytically.
\item The integrand is given in terms of a table. That is, we are
provided with discrete values of $f(x)$ at $n+1$ data or base
points.
\end{itemize}

The general strategy is:
\begin{itemize}
\item Approximate the integrand $f(x)$ with either a global interpolating
polynomial defined over the whole domain of integration, or a
collection of local interpolating polynomials defined over intervals
that are subtended by a small group of data points.
\item Integrate the interpolating polynomials over their individual
domains of definition.
\end{itemize}

Thus, given $f \in C[a,b]$ compute $I(f) = \int_a^b f(x) dx$.

The way we do this is called numerical integration or numerical quadrature:
\[I(f) \approx I_n(f) = \sum_{i=0}^n a_i f(x_i)\]
$a_i \equiv$ quadrature weights\\
$x_i \equiv$ quadrature points

\textbf{Approach \#1}\\
Fix quadrature points ($x_i$), then choose quadrature weights ($a_i$). Usually fit a polynomial to $f(x_i)$ and integrate.
%
\begin{enumerate}%[a.]
\item \underline{Newton-Cotes}: use a single poly over the entire interval
\item \underline{composite Newton-Cotes}: split the interval
\item \underline{Romberg integration}: extrapolation
\end{enumerate}

\textbf{Approach \#2}\\
For a given $n$, choose the ``best" quadrature points ($x_i$) and quadrature weights ($a_i$):\\
\underline{Gaussian Quadrature}

the \textbf{degree of precision} of a quadrature formula, $I_n(f)$, is the positive integer $m$ s.t.:
\begin{enumerate}
\item $I(p) = I_n(p)$ for every poly of degree $\leq m$.
\item $I(p) \neq I_n(p)$ for some poly of degree $m+1$.
\end{enumerate}
 
 
%--------------------------------------------------------------------
\subsection{Newton-Cotes formula}
 
\underline{idea}: fix $x_0, x_1, \dots, x_n$ then interpolate $f(x)$ by a poly of degree $\leq n$.
%
\begin{align}
I(f) &\approx I_n(f) = I(p_n)\\
\text{true integral } &\approx \text{ N-C formula } = \text{ true integral of interpolating poly}
\end{align}
%
The only error is in the interpolation.

%--------------------------------------------------------------------
\subsection*{Lagrange form}
Choosing Lagrange polynomials prevents us from needing to recalculate weights for every $f(x)$ (since we've fixed the points).

\begin{align}
P_n(x) &= \sum_{i=0}^{n}f(x_i)L_i(x) \\
%
I(P_n(x)) &= \sum_{i=0}^{n} \bigl[ \int_a^b L_i(x)dx \bigr] f(x_i) \\
%
&= \sum_{i=0}^{n} a_i f(x_i)\\
\text{where } a_i &=  \int_a^b L_i(x)dx \qquad \therefore a_i \text{ are not dependent on } f(x)
\end{align}

%--------------------------------------------------------------------
\subsubsection{Trapezoid Rule}
This is the Lagrange form of Newton-Cotes integration with $n=1$.

$x_0 = a$, $x_1 = b$, $h = x_1 - x_0$
%
\begin{align}
&L_0(x) = \frac{x-x_1}{x_0-x_1} \qquad L_1(x) = \frac{x-x_0}{x_1-x_0} \\
%
a_0 &= \int_{x_0}^{x_1} \bigl(\frac{x-x_1}{x_0-x_1}\bigr) dx \qquad \text{let } x = x_0 + th \:; dx = hdt \\
%
a_0 &= h \int_0^1 \bigl(\frac{x_1 - x_0 - ht}{h}dt = \int_0^1 h(1-t)dt \\
%
a_0 &= h\bigl(t - \frac{1}{2}t^2 \bigr) |_0^1 = \frac{1}{2}h\\
%
a_1 &= \int_{x_0}^{x_1} \bigl(\frac{x-x_0}{x_1-x_0}\bigr) dx = \frac{1}{2}h\\
%
& \therefore I_1(f) = \frac{h}{2}\bigl(f(x_0) + f(x_1)\bigr) \rightarrow \text{area of a trapezoid}
\end{align}

The trapezoid rule has 1 as its degree of precision.

\textbf{draw picture}

%--------------------------------------------------------------------
\subsubsection{Simpson's Rule}
 
%--------------------------------------------------------------------
%--------------------------------------------------------------------
%\bibliographystyle{plain}
%\bibliography{LinearSolns} 

\end{document}