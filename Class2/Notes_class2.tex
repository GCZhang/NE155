\documentclass[12pt, ]{article}

\title{NE 155, Class 2, S14}
\author{Rachel Slaybaugh}
\date{January 24, 2014}

\usepackage{setspace}
\onehalfspacing

\begin{document}
\maketitle

\noindent \textbf{How do we measure utility?}

IPS is often specified in the millions, giving MIPS. MIPS is used to measure the integer performance of a computer. Examples of integer operation include data movement (A to B) or value testing (If $A = B$, then $C$). MIPS as a performance benchmark is adequate for the computer when it is used in database query, word processing, spreadsheets, or to run multiple virtual operating systems (http://en.wikipedia.org/wiki/FLOPS).

The clock rate of a CPU is normally determined by the frequency of an oscillator crystal. Typically a crystal oscillator produces a fixed sine wave - the frequency reference signal. Electronic circuitry translates that into a square wave at the same frequency for digital electronics applications (or, in using a CPU multiplier, some fixed multiple of the crystal reference frequency). The clock distribution network inside the CPU carries that clock signal to all the parts that need it. (http://en.wikipedia.org/wiki/Clock\_rate)

FLOPS measures the computing ability of a computer and includes the concept of clock rate. An example of a floating-point operation is the calculation of mathematical equations; as such, FLOPS is a useful measure of supercomputer performance. This is the term we will use most frequently in this class. 

\begin{equation}
FLOPS = cores \times clock \times \frac{FLOPs}{cycle} \nonumber
\end{equation}

%------------------------------------------------------
\vspace*{2em}
\noindent \textbf{Computing Machines, Origins}

Devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. The earliest counting device was probably a form of tally stick. 

The abacus was a key early invention used for arithmetic tasks. What we now call the Roman abacus was used in Babylonia as early as 2400 BC. This was the first known computer: the construction of a tool that extended computation beyond one-to-one correspondence. 

Following the abacus there were a series of analog computers - machines designed to aid in the computation of specific tasks. These were found in ancient China, India, Greece, etc. None of the early computational devices were really computers in the modern sense, but they took the concept of building a tool to do computation, and extended it to complex machinery.

Scottish mathematician and physicist John Napier discovered that the multiplication and division of numbers could be performed by the addition and subtraction, respectively, of the logarithms of those numbers. The slide rule was thus invented in the 1620s to allow multiplication and division operations to be carried out significantly faster than was previously possible. Now we're combining machines with improved ways to think about computation.

 (http://en.wikipedia.org/wiki/History\_of\_computing,\\ http://en.wikipedia.org/wiki/History\_of\_computing\_hardware\\
 \#Punched\_card\_data\_processing)

%------------------------------------------------------
\vspace*{2em}
\noindent \textbf{Early Development of Computing}
Next mechanical calculators, punched card data processing, and calculators using electric motors were developed. 

Charles Babbage, an English mechanical engineer, originated the concept of a programmable computer. Considered the ``father of the computer", he conceptualized and invented the first mechanical computer in the early 19th century. After working on his revolutionary difference engine, designed to aid in navigational calculations, in 1833 he realized that a much more general design, an Analytical Engine, was possible. The input of programs and data was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms. For output, the machine had a printer, a curve plotter, and a bell. The machine was also be able to punch numbers onto cards to be read in later. 

%------------------------------------------------------
\vspace*{2em}
\noindent \textbf{First Electromechanical Computer}

The era of modern computing began with a flurry of development before and during World War II. 

The Z3 was an electromechanical computer designed by Konrad Zuse and was completed in Berlin in 1941. It was the world's first working programmable, fully automatic digital computer. The Z3 was built with 2000 relays, implementing 22-bit words that operated at a clock frequency of about 5â€“10 Hz. Program code and data were stored on punched film. (en.wikipedia.org/wiki/Z3\_(computer))

The ENIAC (Electronic Numerical Integrator And Computer) was the first electronic programmable computer built in the U.S., announced to the public in 1946. It was digital, and capable of being reprogrammed (defined by the states of its patch cables and switches) to solve a full range of computing problems. %It could add or subtract 5000 times a second, a thousand times faster than any other machine. It also had modules to multiply, divide, and square root. High speed memory was limited to 20 words (about 80 bytes). Built under the direction of John Mauchly and J. Presper Eckert at the University of Pennsylvania, ENIAC's development and construction lasted from 1943 to full operation at the end of 1945. 
The machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors.

%------------------------------------------------------
\vspace*{2em}
\noindent \textbf{Stored Programs}

Early computing machines had fixed programs. For example, a desk calculator is a fixed program computer. It can do basic mathematics, but it cannot be used as a word processor or a gaming console. A stored-program computer includes by design an instruction set and can store in memory a set of instructions (a program) that details the computation.

The Manchester Small-Scale Experimental Machine, nicknamed Baby, was the world's first stored-program computer. It was built at the Victoria University of Manchester by Frederic C. Williams, Tom Kilburn and Geoff Tootill, and ran its first program on 21 June 1948. It had a demonstrated speed of 1.1 kIPS.

%Although the computer was considered "small and primitive" by the standards of its time, 
It was the first working machine to contain all of the elements essential to a modern electronic computer. As soon as the SSEM had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a more usable computer, the Manchester Mark 1. The Mark 1 in turn quickly became the prototype for the Ferranti Mark 1, the world's first commercially available, general-purpose computer.

The first application of a computer in an office environment was in 1951. By 1954 IBM introduced a ``smaller", ``more affordable" computer that proved very popular. The IBM 650 weighed over 900 kg, the attached power supply weighed around 1350 kg and both were held in separate cabinets of roughly 1.5 meters by 0.9 meters by 1.8 meters. It cost \$500,000 (\$4.35 million in 2014 \$s) or could be leased for \$3,500 a month (\$30,000 in 2014 \$s).


%------------------------------------------------------
\vspace*{2em}
\noindent \textbf{Microprogramming, Magnetic Storage, Transistors}

Transistorized electronics improved not only the CPU, but also the peripheral devices. Removable / interchangeable disks could be made, which meant that much more data could be kept on hand.
%The second generation disk data storage units were able to store tens of millions of letters and digits. Next to the fixed disk storage units, connected to the CPU via high-speed data transmission, were removable disk data storage units. A removable disk pack can be easily exchanged with another pack in a few seconds. Even if the removable disks' capacity is smaller than fixed disks, their interchangeability guarantees a nearly unlimited quantity of data close at hand. Magnetic tape provided archival capability for this data, at a lower cost than disk.

%------------------------------------------------------
\vspace*{2em}
\noindent \textbf{Supercomputers}

The early 1960s saw the advent of supercomputing. The Atlas Computer was a joint development between the University of Manchester, Ferranti, and Plessey, and was first installed at Manchester University and officially commissioned in 1962 as one of the world's first supercomputers% - considered to be the most powerful computer in the world at that time. It was a second-generation machine, using discrete germanium transistors. Atlas also pioneered the Atlas Supervisor, "considered by many to be the first recognisable modern operating system".

In the U.S., a series of computers at Control Data Corporation (CDC) were designed by Seymour Cray to use innovative designs and parallelism to achieve superior computational peak performance.

The CDC 6600 was a mainframe computer delivered in 1965 to CERN, where it was used to analyse the 2-3 million photographs of bubble-chamber tracks that CERN experiments were producing every year. In 1966 another CDC 6600 was delivered to the Lawrence Radiation Laboratory, part of the University of California at Berkeley, where it was used for the analysis of nuclear events photographed inside the Alvarez bubble chamber. The CDC 6600 is generally considered to be the first successful supercomputer. the CDC 6600 was the world's fastest computer from 1964 to 1969.

%------------------------------------------------------
\vspace*{2em}
\noindent \textbf{Integrated Circuit}

This new development heralded an explosion in the commercial and personal use of computers and led to the invention of the microprocessor. While the earliest microprocessor ICs literally contained only the processor, i.e. the central processing unit, of a computer, their progressive development naturally led to chips containing most or all of the internal electronic parts of a computer.

This revolution led to the third generation of computers, and the developments since then have been more familiar. 

%------------------------------------------------------
%\vspace*{2em}
%\noindent \textbf{Types of Memory}
%
%Read-only memory (ROM) is a class of storage medium used in computers and other electronic devices. Data stored in ROM cannot be modified, or can be modified only slowly or with difficulty, so it is mainly used to distribute firmware (software that is very closely tied to specific hardware, and unlikely to need frequent updates). (http://en.wikipedia.org/wiki/Read-only\_memory)
%
%Dynamic random-access memory (DRAM) is a type of random-access memory that stores each bit of data in a separate capacitor within an integrated circuit.% The capacitor can be either charged or discharged; these two states are taken to represent the two values of a bit, conventionally called 0 and 1. Since even "nonconducting" transistors always leak a small amount, the capacitors will slowly discharge, and the information eventually fades unless the capacitor charge is refreshed periodically. Because of this refresh requirement, it is a dynamic memory as opposed to SRAM and other static memory.
%%
%%The main memory (the "RAM") in personal computers is dynamic RAM (DRAM). It is the RAM in desktops, laptops and workstation computers as well as some of the RAM of video game consoles.
%%
%%The advantage of DRAM is its structural simplicity: only one transistor and a capacitor are required per bit, compared to four or six transistors in SRAM. This allows DRAM to reach very high densities. Unlike flash memory, DRAM is volatile memory (vs. non-volatile memory), since it loses its data quickly when power is removed. The transistors and capacitors used are extremely small; billions can fit on a single memory chip. 
%(http://en.wikipedia.org/wiki/DRAM)
%
%Many computer systems have a memory hierarchy consisting of CPU registers, on-die SRAM caches, external caches, DRAM, paging systems and virtual memory or swap space on a hard drive. This entire pool of memory may be referred to as "RAM" by many developers, even though the various subsystems can have very different access times, violating the original concept behind the random access term in RAM. Even within a hierarchy level such as DRAM, the specific row, column, bank, rank, channel, or interleave organization of the components make the access time variable, although not to the extent that rotating storage media or a tape is variable. (en.wikipedia.org/wiki/RAM\#Memory\_hierarchy)



%------------------------------------------------------
\vspace*{2em}
\noindent \textbf{Types of Memory}

In a distributed memory system there is typically a processor, a memory, and some form of interconnection that allows programs on each processor to interact with each other. The interconnect can be organised with point to point links or separate hardware can provide a switching network. The network topology is a key factor in determining how the multi-processor machine scales. The links between nodes can be implemented using some standard network protocol (for example Ethernet), using bespoke network links (used in for example the Transputer), or using dual ported memories.

The key issue in programming distributed memory systems is how to distribute the data over the memories. Depending on the problem solved, the data can be distributed statically, or it can be moved through the nodes. Data can be moved on demand, or data can be pushed to the new nodes in advance. 

The advantage of (distributed) shared memory is that it offers a unified address space in which all data can be found.

The advantage of distributed memory is that it excludes race conditions, and that it forces the programmer to think about data distribution.

The advantage of distributed (shared) memory is that it is easier to design a machine that scales with the algorithm

Distributed shared memory hides the mechanism of communication - it does not hide the latency of communication.

(http://en.wikipedia.org/wiki/Distributed\_memory)

\end{document}
